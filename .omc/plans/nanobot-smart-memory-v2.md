# Nanobot æ™ºèƒ½è®°å¿†ç³»ç»Ÿ v2.0

> çŠ¶æ€: **Final Plan**
> åˆ›å»ºæ—¶é—´: 2026-02-11
> æŠ€æœ¯æ ˆ: çº¯ Python (sentence-transformers + ChromaDB)

> è¡¥å……è¯´æ˜ï¼ˆå®ç°å‘ï¼‰ï¼šæœ¬æ–‡ä»¶åœ¨ v2.0 æ–¹æ¡ˆåŸºç¡€ä¸Šè¡¥é½å¯è½åœ°ç»†èŠ‚ï¼ˆæ•°æ®æ¨¡å‹ã€ç´¢å¼•ç”Ÿå‘½å‘¨æœŸã€é™çº§ç­–ç•¥ã€é…ç½®å¯¹é½ç­‰ï¼‰ï¼Œå¹¶ä¿®æ­£ç¤ºä¾‹ä»£ç ä¸­ã€Œæ£€ç´¢è¿”å›å€¼ã€ä¸ã€Œåˆ†å±‚é€»è¾‘ã€ä¸ä¸€è‡´çš„é—®é¢˜ã€‚

---

## ä¸€ã€æ–¹æ¡ˆæ¦‚è¿°

### 1.1 ä¸ v1.0 çš„å˜åŒ–

| ç»´åº¦ | v1.0 (QMD) | v2.0 (çº¯ Python) |
|------|------------|------------------|
| Embedding | QMD æœ¬åœ°æ¨¡å‹ | sentence-transformers |
| å‘é‡å­˜å‚¨ | QMD sqlite-vec | ChromaDB |
| è¿è¡Œæ—¶ | Bun + Node.js | **çº¯ Python** |
| æ¨¡å‹å¤§å° | ~2GB | **~118MB** |
| å®‰è£… | bun install | **pip install** |

### 1.2 æ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                Nanobot Smart Memory v2.0                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  å†™å…¥å±‚              å­˜å‚¨å±‚              æ£€ç´¢å±‚                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ AgentHooks  â”‚    â”‚ Markdown    â”‚    â”‚ Hybrid Search       â”‚ â”‚
â”‚  â”‚ â”œâ”€ToolObs   â”‚â”€â”€â”€â–¶â”‚ Files       â”‚â—€â”€â”€â”€â”‚ â”œâ”€ BM25 (FTS5)      â”‚ â”‚
â”‚  â”‚ â””â”€Summary   â”‚    â”‚ (ä¸å˜)      â”‚    â”‚ â””â”€ Vector (Chroma)  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                            â”‚                    â–²               â”‚
â”‚                            â–¼                    â”‚               â”‚
â”‚                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚                     â”‚ .storage/   â”‚    â”‚ sentence-transformersâ”‚ â”‚
â”‚                     â”‚ â”œâ”€ chroma/  â”‚    â”‚ multilingual-MiniLM â”‚ â”‚
â”‚                     â”‚ â””â”€ fts.db   â”‚    â”‚ (118MB æœ¬åœ°)        â”‚ â”‚
â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## äºŒã€æŠ€æœ¯é€‰å‹

### 2.1 Embedding æ¨¡å‹

**é€‰æ‹©ï¼š`paraphrase-multilingual-MiniLM-L12-v2`**

| å±æ€§ | å€¼ |
|------|----|
| å¤§å° | 118MB |
| ç»´åº¦ | 384 |
| è¯­è¨€ | 50+ (å«ä¸­è‹±æ–‡) |
| ä¸‹è½½é‡ | 1800ä¸‡+ |

### 2.2 ä¾èµ–

```bash
pip install sentence-transformers chromadb
```

---

## ä¸‰ã€æ–‡ä»¶ç»“æ„

### æ–°å¢æ–‡ä»¶

```
nanobot/
â”œâ”€â”€ agent/
â”‚   â”œâ”€â”€ hooks.py           # Agent ç”Ÿå‘½å‘¨æœŸ Hooks
â”‚   â”œâ”€â”€ observation.py     # å·¥å…·è§‚å¯Ÿè®°å½•
â”‚   â”œâ”€â”€ summarizer.py      # ä¼šè¯æ‘˜è¦ç”Ÿæˆ
â”‚   â”œâ”€â”€ memory.py          # HybridMemoryStore (é‡æ„)
â”‚   â””â”€â”€ retrieval.py       # æ··åˆæ£€ç´¢
â”œâ”€â”€ storage/
â”‚   â”œâ”€â”€ embedding.py       # Embedding æœåŠ¡
â”‚   â”œâ”€â”€ vectorstore.py     # ChromaDB å°è£…
â”‚   â””â”€â”€ fts.py             # FTS5 å…¨æ–‡æœç´¢
```

### æ•°æ®å­˜å‚¨

```
workspace/
â”œâ”€â”€ memory/                 # Markdown (ä¸å˜)
â”‚   â”œâ”€â”€ MEMORY.md
â”‚   â””â”€â”€ 2026-02-11.md
â”œâ”€â”€ .storage/               # æ–°å¢ï¼šç´¢å¼•
â”‚   â”œâ”€â”€ chroma/
â”‚   â”œâ”€â”€ fts.sqlite3
â”‚   â””â”€â”€ manifest.jsonl       # ç´¢å¼•æ¸…å•ï¼ˆå¹‚ç­‰/å¢é‡/åˆ é™¤ï¼‰
```

---

## å››ã€æ ¸å¿ƒæ¨¡å—

### 4.1 Embedding æœåŠ¡

```python
# nanobot/storage/embedding.py

from sentence_transformers import SentenceTransformer

class LocalEmbedding:
    MODELS = {
        "multilingual": "paraphrase-multilingual-MiniLM-L12-v2",  # 118MB
        "chinese": "BAAI/bge-small-zh-v1.5",  # 95MB
        "english": "all-MiniLM-L6-v2",  # 22MB
    }

    def __init__(self, model_name: str = "multilingual"):
        actual_model = self.MODELS.get(model_name, model_name)
        self.model = SentenceTransformer(actual_model)
        self.dimension = self.model.get_sentence_embedding_dimension()

    def embed(self, text: str) -> list[float]:
        return self.model.encode(text).tolist()

    def embed_batch(self, texts: list[str]) -> list[list[float]]:
        return self.model.encode(texts).tolist()
```

### 4.2 å‘é‡å­˜å‚¨ (ChromaDB)

```python
# nanobot/storage/vectorstore.py

import chromadb
from dataclasses import dataclass

@dataclass
class VectorSearchResult:
    id: str
    text: str
    score: float
    metadata: dict

class VectorStore:
    def __init__(self, storage_path: Path, embedding: LocalEmbedding):
        self.embedding = embedding
        self.client = chromadb.PersistentClient(path=str(storage_path))
        self.collection = self.client.get_or_create_collection("memory")

    def add(self, text: str, metadata: dict = None) -> str:
        doc_id = hashlib.md5(text.encode()).hexdigest()[:12]
        embedding = self.embedding.embed(text)
        self.collection.add(
            ids=[doc_id],
            embeddings=[embedding],
            documents=[text],
            metadatas=[metadata or {}]
        )
        return doc_id

    def search(self, query: str, limit: int = 5) -> list[VectorSearchResult]:
        query_embedding = self.embedding.embed(query)
        results = self.collection.query(
            query_embeddings=[query_embedding],
            n_results=limit
        )
        # è½¬æ¢è·ç¦»ä¸ºç›¸ä¼¼åº¦
        return [
            VectorSearchResult(
                id=results["ids"][0][i],
                text=results["documents"][0][i],
                score=1 / (1 + results["distances"][0][i]),
                metadata=results["metadatas"][0][i]
            )
            for i in range(len(results["ids"][0]))
        ]
```

### 4.3 å…¨æ–‡æœç´¢ (FTS5)

```python
# nanobot/storage/fts.py

import sqlite3

class FullTextSearch:
    def __init__(self, db_path: Path):
        self.conn = sqlite3.connect(str(db_path))
        self._init_tables()

    def _init_tables(self):
        self.conn.execute("""
            CREATE VIRTUAL TABLE IF NOT EXISTS docs_fts
            USING fts5(id, text, title, source)
        """)

    def add(self, text: str, doc_id: str, title: str = ""):
        self.conn.execute(
            "INSERT INTO docs_fts VALUES (?, ?, ?, ?)",
            (doc_id, text, title, "")
        )
        self.conn.commit()

    def search(self, query: str, limit: int = 10):
        cursor = self.conn.execute("""
            SELECT
                id,
                text,
                bm25(docs_fts) as bm25_score,
                snippet(docs_fts, 1, '[', ']', '...', 12) as snippet
            FROM docs_fts
            WHERE docs_fts MATCH ?
            ORDER BY bm25_score LIMIT ?
        """, (query, limit))
        return cursor.fetchall()
```

### 4.4 æ··åˆæ£€ç´¢ï¼ˆä¿®è®¢ï¼šç»Ÿä¸€è¿”å›ç»“æ„ + æŒ‰ rank åˆ†å±‚ï¼‰

```python
# nanobot/agent/retrieval.py

from dataclasses import dataclass, field
from pathlib import Path
from typing import Any


@dataclass
class RetrievedChunk:
    """
    æ··åˆæ£€ç´¢çš„ç»Ÿä¸€è¿”å›ç»“æ„ï¼Œç”¨äºåç»­çš„åˆ†å±‚ã€è£å‰ªä¸ä¸Šä¸‹æ–‡æ ¼å¼åŒ–ã€‚

    è¯´æ˜ï¼š
    - RRF çš„åˆ†æ•°æ˜¯ rank èåˆåˆ†æ•°ï¼Œé‡çº§é€šå¸¸è¿œå°äº 0.5ï¼Œå› æ­¤ä¸å»ºè®®ç”¨ 0.5/0.3
      è¿™ç§é˜ˆå€¼åšåˆ†å±‚ï¼›åˆ†å±‚æ›´æ¨èæŒ‰ rank/top-k æ¥åšã€‚
    """

    id: str
    text: str
    fused_score: float = 0.0
    metadata: dict[str, Any] = field(default_factory=dict)
    snippet: str | None = None
    is_full: bool = False


class HybridRetrieval:
    def __init__(self, workspace: Path, embedding_model: str = "multilingual"):
        self.embedding = LocalEmbedding(embedding_model)
        self.vector_store = VectorStore(workspace / ".storage/chroma", self.embedding)
        self.fts = FullTextSearch(workspace / ".storage/fts.sqlite3")

    def index_document(self, text: str, title: str = "", metadata: dict[str, Any] | None = None) -> str:
        """
        å°†æ–‡æ¡£åŒæ—¶å†™å…¥ VectorStore ä¸ FTSã€‚

        çº¦å®šï¼šè¿”å›çš„ doc_id å¿…é¡»åœ¨ä¸¤å¥—ç´¢å¼•ä¸­ä¸€è‡´ï¼Œä¾¿äº RRF èåˆä¸åˆ é™¤/æ›´æ–°ã€‚
        """
        doc_id = self.vector_store.add(text=text, metadata={"title": title, **(metadata or {})})
        self.fts.add(text=text, doc_id=doc_id, title=title)
        return doc_id

    def search(self, query: str, limit: int = 10, prefetch_multiplier: int = 2) -> list[RetrievedChunk]:
        # 1) å‘é‡æœç´¢ï¼ˆæ›´æ“…é•¿è¯­ä¹‰ï¼‰
        vector_results = self.vector_store.search(query, limit * prefetch_multiplier)

        # 2) å…¨æ–‡æœç´¢ï¼ˆæ›´æ“…é•¿å…³é”®è¯ï¼›é¡ºä¾¿æ‹¿ snippet å……å½“â€œæ‘˜è¦â€ï¼‰
        # fts_results: list[tuple[id, text, bm25_score, snippet]]
        fts_results = self.fts.search(query, limit * prefetch_multiplier)

        # 3) RRF èåˆï¼ˆåªç”¨ rankï¼Œä¸ä¾èµ– bm25 æ•°å€¼é‡çº§ï¼‰
        fused_scores = self._rrf_scores(vector_results, fts_results, k=60)

        by_id: dict[str, RetrievedChunk] = {}

        # Prefer vector store text as "full text" source
        for r in vector_results:
            by_id[r.id] = RetrievedChunk(
                id=r.id,
                text=r.text,
                fused_score=fused_scores.get(r.id, 0.0),
                metadata=r.metadata,
            )

        # Attach snippet from FTS (cheap "æ‘˜è¦") and fallback to FTS text if missing
        for doc_id, text, _bm25_score, snippet in fts_results:
            chunk = by_id.get(doc_id)
            if not chunk:
                chunk = RetrievedChunk(id=doc_id, text=text, fused_score=fused_scores.get(doc_id, 0.0))
                by_id[doc_id] = chunk
            if snippet:
                chunk.snippet = snippet

        ordered = sorted(by_id.values(), key=lambda c: c.fused_score, reverse=True)
        return ordered[:limit]

    def _rrf_scores(self, vec_results, fts_results, k: int = 60) -> dict[str, float]:
        """Reciprocal Rank Fusionï¼ˆåªç”¨ rank èåˆï¼Œé¿å…ä¸åŒ score é‡çº§ä¸ä¸€è‡´ï¼‰"""
        scores: dict[str, float] = {}
        for rank, r in enumerate(vec_results, 1):
            scores[r.id] = scores.get(r.id, 0.0) + 1.0 / (k + rank)
        for rank, r in enumerate(fts_results, 1):
            doc_id = r[0]
            scores[doc_id] = scores.get(doc_id, 0.0) + 1.0 / (k + rank)
        return scores

    def progressive_retrieve(
        self,
        query: str,
        max_full_docs: int = 3,
        max_snippets: int = 5,
    ) -> list[RetrievedChunk]:
        """ä¸¤æ®µå¼æ¸è¿›æ£€ç´¢ï¼štop-k å…¨æ–‡ + åç»­ snippet/æˆªæ–­æ–‡æœ¬"""
        results = self.search(query, limit=max_full_docs + max_snippets)
        for r in results[:max_full_docs]:
            r.is_full = True
        return results
```

### 4.5 Agent Hooks

```python
# nanobot/agent/hooks.py

from abc import ABC
from dataclasses import dataclass
from datetime import datetime

@dataclass
class ToolExecution:
    tool_name: str
    arguments: dict
    result: str
    error: Exception | None
    timestamp: datetime
    duration_ms: float
    session_key: str

class AgentHook(ABC):
    async def on_message_received(self, session_key, content): pass
    async def on_tool_executed(self, execution: ToolExecution): pass
    async def on_session_end(self, session_key, history, response): pass

class HookManager:
    def __init__(self):
        self._hooks = []

    def register(self, hook: AgentHook):
        self._hooks.append(hook)

    async def emit_tool_executed(self, execution):
        for hook in self._hooks:
            await hook.on_tool_executed(execution)
```

### 4.6 è§‚å¯Ÿè®°å½• Hook

```python
# nanobot/agent/observation.py

SIGNIFICANT_TOOLS = {"write_file", "edit_file", "exec"}

class ObservationHook(AgentHook):
    def __init__(self, memory_dir: Path, retrieval: HybridRetrieval):
        self.memory_dir = memory_dir
        self.retrieval = retrieval

    async def on_tool_executed(self, execution: ToolExecution):
        if execution.tool_name not in SIGNIFICANT_TOOLS:
            return
        if execution.error:
            return

        # ç”Ÿæˆè§‚å¯Ÿå†…å®¹
        content = self._format(execution)

        # 1. å†™å…¥ Markdown
        self._write_markdown(content)

        # 2. ç´¢å¼•åˆ°å‘é‡åº“
        self.retrieval.index_document(content, title=execution.tool_name)

    def _format(self, exec):
        return f"""## ğŸ”§ {exec.tool_name} @ {exec.timestamp:%H:%M}

**\1**: {exec.arguments}
**\1**: {exec.result[:300]}...
"""
```

### 4.7 ä¼šè¯æ‘˜è¦ Hook

```python
# nanobot/agent/summarizer.py

SUMMARY_PROMPT = """Summarize this conversation:
1. What user wanted
2. Key actions taken
3. Outcome
Keep under 200 words.

{conversation}
"""

class SummaryHook(AgentHook):
    def __init__(self, memory_dir, retrieval, provider, min_turns=3):
        self.memory_dir = memory_dir
        self.retrieval = retrieval
        self.provider = provider
        self.min_turns = min_turns

    async def on_session_end(self, session_key, history, response):
        if len([m for m in history if m["role"]=="user"]) < self.min_turns:
            return

        # ç”Ÿæˆæ‘˜è¦
        summary = await self._generate_summary(history)

        # å†™å…¥ MEMORY.md
        self._save(session_key, summary)

        # ç´¢å¼•
        self.retrieval.index_document(summary, title=f"Session: {session_key}")

    async def _generate_summary(self, history):
        conv = "\n".join(f"{m['role']}: {m['content'][:500]}" for m in history)
        resp = await self.provider.chat([{"role": "user", "content": SUMMARY_PROMPT.format(conversation=conv)}])
        return resp.content
```

### 4.8 æ··åˆè®°å¿†å­˜å‚¨

```python
# nanobot/agent/memory.py

class HybridMemoryStore:
    def __init__(self, workspace: Path, embedding_model="multilingual"):
        self.workspace = workspace
        self.memory_dir = workspace / "memory"
        self._retrieval = None
        self._model = embedding_model

    def initialize(self):
        self.memory_dir.mkdir(parents=True, exist_ok=True)
        self._retrieval = HybridRetrieval(self.workspace, self._model)
        self._index_existing_files()

    @property
    def retrieval(self):
        if not self._retrieval:
            self.initialize()
        return self._retrieval

    async def get_context(self, query: str = None) -> str:
        """è·å–è®°å¿†ä¸Šä¸‹æ–‡"""
        parts = []

        # è¯­ä¹‰æ£€ç´¢
        if query:
            results = self.retrieval.progressive_retrieve(query)
            if results:
                parts.append(self.retrieval.format_context(results))

        # é•¿æœŸè®°å¿†å¤´éƒ¨
        if (self.memory_dir / "MEMORY.md").exists():
            content = (self.memory_dir / "MEMORY.md").read_text()[-1000:]
            parts.append(f"## Long-term Memory\n{content}")

        return "\n\n---\n\n".join(parts)
```

---

## äº”ã€AgentLoop é›†æˆ

```python
# nanobot/agent/loop.py (ä¿®æ”¹)

class AgentLoop:
    def __init__(self, ..., enable_observations=True, enable_summaries=True):
        # åˆå§‹åŒ–è®°å¿†
        self.memory = HybridMemoryStore(workspace)

        # åˆå§‹åŒ– Hooks
        self.hooks = HookManager()

        if enable_observations:
            self.hooks.register(ObservationHook(
                workspace / "memory",
                self.memory.retrieval
            ))

        if enable_summaries:
            self.hooks.register(SummaryHook(
                workspace / "memory",
                self.memory.retrieval,
                provider
            ))

    async def run(self):
        self.memory.initialize()  # åŠ è½½ embedding æ¨¡å‹
        # ...

    async def _process_message(self, msg):
        # ä½¿ç”¨è¯­ä¹‰æ£€ç´¢æ„å»ºä¸Šä¸‹æ–‡
        memory_context = await self.memory.get_context(query=msg.content)

        # ... ç°æœ‰é€»è¾‘ ...

        for tool_call in response.tool_calls:
            start = time.time()
            result = await self.tools.execute(tool_call.name, tool_call.arguments)
            duration = (time.time() - start) * 1000

            # è§¦å‘ Hook
            await self.hooks.emit_tool_executed(ToolExecution(
                tool_name=tool_call.name,
                arguments=tool_call.arguments,
                result=result,
                error=None,
                timestamp=datetime.now(),
                duration_ms=duration,
                session_key=msg.session_key
            ))

        # ä¼šè¯ç»“æŸ
        await self.hooks.emit_session_end(
            session_key=msg.session_key,
            history=session.messages,
            response=final_content
        )
```

---

## å…­ã€é…ç½®

> è¯´æ˜ï¼šnanobot å½“å‰ä½¿ç”¨ `~/.nanobot/config.json`ï¼ˆcamelCaseï¼‰ã€‚å»ºè®®å°† memory é…ç½®çº³å…¥ `nanobot/config/schema.py`ï¼Œå¹¶é€šè¿‡ç°æœ‰ loader çš„ key è½¬æ¢/è¿ç§»é€»è¾‘ä¿æŒå…¼å®¹ã€‚

```json
{
  "memory": {
    "enabled": true,
    "embeddingModel": "multilingual",
    "enableObservations": true,
    "enableSummaries": true,
    "summaryMinTurns": 3,
    "isolateBySession": false,
    "retrieval": {
      "limit": 8,
      "maxFullDocs": 3,
      "maxSnippets": 5,
      "rrfK": 60,
      "prefetchMultiplier": 2
    }
  }
}
```

---

## ä¸ƒã€å®‰è£…ä¸ä½¿ç”¨

### å®‰è£…

```bash
# å®‰è£… nanobot æ—¶åŒ…å« memory åŠŸèƒ½
pip install nanobot[memory]

# æˆ–å•ç‹¬å®‰è£…ä¾èµ–
pip install sentence-transformers chromadb
```

### é¦–æ¬¡è¿è¡Œ

é¦–æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä¸‹è½½ embedding æ¨¡å‹ (~118MB)ï¼š

```
~/.cache/huggingface/hub/
â””â”€â”€ models--sentence-transformers--paraphrase-multilingual-MiniLM-L12-v2/
```

---

## å…«ã€å®æ–½è®¡åˆ’

| Phase | å†…å®¹ | æ—¶é—´ |
|-------|------|------|
| 1 | å­˜å‚¨å±‚ (embedding, vectorstore, fts) | 1 å¤© |
| 2 | æ£€ç´¢å±‚ (retrieval, memory) | 1 å¤© |
| 3 | Hooks (hooks, observation, summarizer) | 1 å¤© |
| 4 | é›†æˆ (loop ä¿®æ”¹, æµ‹è¯•) | 1 å¤© |

**æ€»è®¡ï¼š4 å¤©**

---

## ä¹ã€éªŒæ”¶æ ‡å‡†

- [ ] `pip install nanobot[memory]` æˆ– `pip install sentence-transformers chromadb` æˆåŠŸ
- [ ] Embedding æ¨¡å‹è‡ªåŠ¨ä¸‹è½½å¹¶åŠ è½½
- [ ] å‘é‡æœç´¢è¿”å›ç›¸å…³ç»“æœ
- [ ] å…¨æ–‡æœç´¢æ­£å¸¸å·¥ä½œï¼ˆå« snippet/é«˜äº®ç‰‡æ®µè¿”å›ï¼‰
- [ ] æ··åˆæœç´¢ RRF èåˆæ­£ç¡®
- [ ] å·¥å…·è§‚å¯Ÿè‡ªåŠ¨è®°å½•åˆ° Markdown
- [ ] å·¥å…·è§‚å¯Ÿè‡ªåŠ¨ç´¢å¼•åˆ°å‘é‡åº“
- [ ] ä¼šè¯æ‘˜è¦ç”Ÿæˆå¹¶ä¿å­˜
- [ ] é‡å¯/é‡å¤è¿è¡Œä¸ä¼šé€ æˆç´¢å¼•è†¨èƒ€ï¼ˆå¹‚ç­‰ï¼šç›¸åŒè¾“å…¥ doc æ•°ä¸å¢é•¿ï¼‰
- [ ] æ–‡ä»¶æ›´æ–°/åˆ é™¤å¯è§¦å‘å¯¹åº”ç´¢å¼•æ›´æ–°/åˆ é™¤ï¼ˆmanifest æˆ–ç­‰ä»·æœºåˆ¶ï¼‰
- [ ] Embedding/Chroma ä¸å¯ç”¨æ—¶å¯é™çº§ï¼ˆè‡³å°‘ä¿ç•™ FTS æˆ–çº¯ Markdown è®°å¿†ï¼‰
- [ ] Token æ¶ˆè€—é™ä½ 50%+ï¼ˆæœ‰åŸºçº¿ã€æ ·æœ¬ä¸ç»Ÿè®¡å£å¾„ï¼‰

---

## åã€ä¼˜åŠ¿æ€»ç»“

| ç»´åº¦ | è¯´æ˜ |
|------|------|
| **çº¯ Python** | æ— éœ€ Bun/Node.js |
| **è½»é‡æ¨¡å‹** | 118MB vs 2GB |
| **ç®€å•å®‰è£…** | pip install |
| **ç¦»çº¿å¯ç”¨** | æœ¬åœ° embedding |
| **ä¸­æ–‡æ”¯æŒ** | å¤šè¯­è¨€æ¨¡å‹ |
| **æ··åˆæ£€ç´¢** | BM25 + å‘é‡ |
| **è‡ªåŠ¨è®°å½•** | Hooks ç³»ç»Ÿ |
| **ä¼šè¯æ‘˜è¦** | LLM ç”Ÿæˆ |

---

## åä¸€ã€å®ç°è¡¥å……ï¼ˆå»ºè®®çº³å…¥ v2.0ï¼‰

### 11.1 ä¿®è®¢å»ºè®®æ¸…å•ï¼ˆé«˜ä¼˜å…ˆçº§ï¼‰

1. **ç»Ÿä¸€æ£€ç´¢è¿”å›ç»“æ„**ï¼š`search()` å¿…é¡»è¿”å›å¯ç”¨äºåˆ†å±‚ä¸æ ¼å¼åŒ–çš„å¯¹è±¡ï¼ˆè€Œä¸æ˜¯ä»…è¿”å› id åˆ—è¡¨ï¼‰ï¼Œé¿å…å®ç°é˜¶æ®µå‡ºç°ç»“æ„ä¸åŒ¹é…ã€‚
2. **æ¸è¿›å¼æ£€ç´¢æ”¹ä¸ºæŒ‰ rank åˆ†å±‚**ï¼šRRF åˆ†æ•°ä¸é€‚åˆä½œä¸º 0.5/0.3 è¿™ç§é˜ˆå€¼åˆ†å±‚ä¾æ®ï¼›æ¨è top-k å…¨æ–‡ + åç»­ snippet çš„ä¸¤æ®µå¼ç­–ç•¥ã€‚
3. **è¡¥é½ç´¢å¼•ç”Ÿå‘½å‘¨æœŸ**ï¼šæ˜ç¡®â€œé¦–æ¬¡å»ºç´¢å¼•ã€å¢é‡æ›´æ–°ã€åˆ é™¤æ¸…ç†ã€å¹‚ç­‰é‡å¯â€çš„æœºåˆ¶ï¼ˆmanifest æˆ– sqlite è¡¨ï¼‰ï¼Œå¦åˆ™ä¸Šçº¿åä¼šå¿«é€Ÿè†¨èƒ€ä¸”éš¾ä»¥ç»´æŠ¤ã€‚
4. **é…ç½®å¯¹é½åˆ°ç°æœ‰ config.json**ï¼šé¿å…å†å¼•å…¥ç¬¬äºŒå¥—é…ç½®å…¥å£ï¼ˆå¦‚ `config.yaml`ï¼‰ï¼Œå‡å°‘ç”¨æˆ·ä¸ç»´æŠ¤æˆæœ¬ã€‚
5. **æä¾›é™çº§è·¯å¾„**ï¼šembedding ä¾èµ–/æ¨¡å‹ä¸‹è½½å¤±è´¥æ—¶ä»å¯è¿è¡Œï¼ˆä¾‹å¦‚ FTS-onlyï¼‰ï¼Œé¿å…å¯åŠ¨å³å´©ã€‚
6. **åŠ å…¥è„±æ•ä¸é™å™ª**ï¼šObservation/Exec è¾“å‡ºå¯èƒ½åŒ…å«å¯†é’¥ä¸éšç§å†…å®¹ï¼Œéœ€åœ¨å†™å…¥ä¸ç´¢å¼•å‰åšæœ€å° redaction + æˆªæ–­ã€‚

### 11.2 æ•°æ®æ¨¡å‹ï¼ˆç»Ÿä¸€ç´¢å¼•/æ£€ç´¢/è¿‡æ»¤ï¼‰

å»ºè®®ä¸ºæ¯ä¸ªè¢«ç´¢å¼•çš„æ–‡æœ¬ç‰‡æ®µï¼ˆchunkï¼‰ç»´æŠ¤æœ€å°å­—æ®µé›†åˆï¼ˆå†™å…¥å‘é‡åº“ metadata + FTS å­—æ®µæˆ–é™„è¡¨ï¼‰ï¼š

- `doc_id`: ç¨³å®šå”¯ä¸€ idï¼ˆå»ºè®®åŒ…å« `source + chunk_index + content_hash`ï¼Œé¿å…ä¸åŒæ¥æºç›¸åŒæ–‡æœ¬äº’ç›¸è¦†ç›–ï¼‰
- `source_type`: `daily_note` | `long_term` | `observation` | `summary`
- `source_path`: åŸå§‹æ–‡ä»¶è·¯å¾„ï¼ˆè‹¥æ¥è‡ªæ–‡ä»¶ï¼‰
- `title`: å±•ç¤ºç”¨æ ‡é¢˜ï¼ˆå·¥å…·å/ä¼šè¯å/æ–‡ä»¶åï¼‰
- `session_key`: å¯é€‰ï¼›ç”¨äºä¼šè¯éš”ç¦»æˆ–è¿‡æ»¤
- `timestamp`: è®°å½•æ—¶é—´ï¼ˆç”¨äºæ’åºã€è¡°å‡ï¼‰
- `content_hash`: ç”¨äºå¹‚ç­‰ä¸å¢é‡æ›´æ–°
- `chunk_index`: åˆ†å—åºå·ï¼ˆé•¿æ–‡åˆ†å—ï¼‰

ç†ç”±ï¼šæ²¡æœ‰ç»Ÿä¸€ metadataï¼Œä¼šå¯¼è‡´â€œèåˆ/è¿‡æ»¤/åˆ é™¤â€åœ¨å®ç°æ—¶å˜æˆä¸´æ—¶è¡¥ä¸ï¼ŒåæœŸè¿”å·¥ä»£ä»·é«˜ã€‚

### 11.3 ç´¢å¼•ç”Ÿå‘½å‘¨æœŸï¼ˆå¹‚ç­‰ + å¢é‡æ›´æ–° + åˆ é™¤ï¼‰

å»ºè®®å¼•å…¥ manifestï¼ˆç¤ºä¾‹ï¼š`workspace/.storage/manifest.jsonl` æˆ– `workspace/.storage/meta.sqlite3`ï¼‰ï¼Œè‡³å°‘è®°å½•ï¼š

- `source_path`ã€`mtime`ã€`file_hash`
- è¯¥æ–‡ä»¶å¯¹åº”çš„ `doc_id[]`ï¼ˆåˆ†å—åå¤šä¸ª idï¼‰

ç´¢å¼•ç­–ç•¥ï¼š

- å¯åŠ¨/å®šæ—¶ï¼šæ‰«æ `workspace/memory/`ï¼Œè‹¥ `mtime/hash` æœªå˜åŒ–åˆ™è·³è¿‡ï¼›å˜åŒ–åˆ™åˆ é™¤æ—§ doc_id å¹¶é‡å»ºã€‚
- åˆ é™¤æ–‡ä»¶ï¼šæ ¹æ® manifest æ‰¾åˆ°æ—§ doc_id å¹¶ä» Chroma + FTS åŒæ­¥åˆ é™¤ã€‚
- è§‚å¯Ÿ/æ‘˜è¦å†™å…¥ï¼šå†™å…¥ Markdown åï¼Œç›´æ¥å¯¹æ–°å¢ chunk åš upsertï¼ˆé¿å…å…¨é‡é‡å»ºï¼‰ã€‚

ç†ç”±ï¼šæ²¡æœ‰ç”Ÿå‘½å‘¨æœŸç®¡ç†ä¼šå¯¼è‡´é‡å¤ç´¢å¼•ã€å¬å›å™ªéŸ³å‡é«˜ã€å‘é‡åº“/FTS ä½“ç§¯è†¨èƒ€ã€æ£€ç´¢å˜æ…¢ã€‚

### 11.4 æ£€ç´¢ç­–ç•¥ä¸ä¸Šä¸‹æ–‡é¢„ç®—ï¼ˆæ›´å¯æ§ï¼‰

- **èåˆé˜¶æ®µåªä½¿ç”¨ rank**ï¼šFTS çš„ `bm25()` é‡çº§/æ­£è´Ÿ/æ–¹å‘ä¸ä¸€å®šä¸å‘é‡ç›¸ä¼¼åº¦ä¸€è‡´ï¼›èåˆç”¨ RRF rank æ›´ç¨³ã€‚
- **ä¸­ç­‰ç›¸å…³ç”¨ snippet**ï¼šå»ºè®® FTS è¿”å› `snippet()` ç‰‡æ®µä½œä¸ºä½æˆæœ¬â€œæ‘˜è¦â€ï¼›å¿…è¦æ—¶å†å¼•å…¥ LLM ç”Ÿæˆæ‘˜è¦ï¼ˆæˆæœ¬æ›´é«˜ï¼‰ã€‚
- **ä¸Šä¸‹æ–‡é¢„ç®—**ï¼šæ„å»º prompt æ—¶æŒ‰é¢„ç®—è£å‰ªï¼ˆPinned long-term -> Relevant recalls -> Recent summaryï¼‰ï¼Œé¿å…æŠŠ `MEMORY.md` å°¾éƒ¨ç¡¬å¡å›ºå®šå­—æ•°é€ æˆå™ªéŸ³ã€‚

### 11.5 ä¾èµ–ä¸é™çº§ç­–ç•¥ï¼ˆé¿å…â€œå®‰è£…å³çˆ†ç‚¸â€ï¼‰

- å»ºè®®æŠŠä¾èµ–ä½œä¸ºå¯é€‰ extraï¼š`nanobot[memory]`ï¼Œå¹¶æä¾›è¿è¡Œæ—¶æ£€æµ‹ã€‚
- `sentence-transformers` å¾€å¾€ä¼šå¸¦æ¥è¾ƒé‡çš„ä¾èµ–ï¼ˆå¦‚ torchï¼‰ï¼›è‹¥â€œè¶…è½»é‡â€æ˜¯ç¡¬çº¦æŸï¼Œå¯å¢åŠ è½»ä¾èµ–å¤‡é€‰ï¼ˆONNX/fastembedï¼‰æˆ– remote embedding + æœ¬åœ°ç¼“å­˜ã€‚
- é™çº§é“¾è·¯å»ºè®®ï¼š`Hybrid(BM25+Vector)` â†’ `FTS-only` â†’ `Markdown-only`ï¼ˆç¡®ä¿è‡³å°‘èƒ½å·¥ä½œï¼‰ã€‚

### 11.6 æ€§èƒ½ä¸å¹¶å‘ï¼ˆasync ä¸é˜»å¡ï¼‰

- ç´¢å¼•ä¸ embedding å»ºè®®æ”¾åˆ°åå°çº¿ç¨‹/é˜Ÿåˆ—ï¼ˆ`asyncio.to_thread` æˆ–å•ç‹¬ workerï¼‰ï¼Œé¿å…é˜»å¡ AgentLoopã€‚
- embedding/å…¥åº“å»ºè®® batch åŒ–ï¼ˆ`embed_batch`ï¼‰ï¼Œå¹¶å¯¹ observation åšæˆªæ–­ä¸å»é‡ï¼ˆå‡å°‘å‘é‡å†™å…¥é‡ï¼‰ã€‚
- SQLite å»ºè®®å¼€å¯ WALï¼Œå¹¶å°†å†™å…¥ä¸²è¡ŒåŒ–ï¼ˆé¿å…å¤šåç¨‹å¹¶å‘å†™å¯¼è‡´é”äº‰ç”¨ï¼‰ã€‚

### 11.7 å®‰å…¨ä¸éšç§ï¼ˆå¿…é¡»é¡¹ï¼‰

- observation/summarizer åœ¨å†™å…¥/ç´¢å¼•å‰åš redactionï¼ˆAPI keyã€tokenã€cookieã€é‚®ç®±ã€æ‰‹æœºå·ç­‰ï¼‰ï¼Œå¹¶æä¾› allowlist/denylist é…ç½®ã€‚
- å¯¹ `exec` å·¥å…·çš„è§‚å¯Ÿé»˜è®¤æ›´ä¿å®ˆï¼ˆåªè®°å½•å‘½ä»¤ä¸å°‘é‡è¾“å‡ºç‰‡æ®µï¼‰ï¼Œé¿å…æŠŠæ•æ„Ÿç¯å¢ƒå˜é‡ä¸å®Œæ•´è¾“å‡ºè¿›å…¥é•¿æœŸè®°å¿†ã€‚

### 11.8 éªŒæ”¶ä¸åŸºå‡†ï¼ˆå¯å¤ç°ï¼‰

- è§„å®šåŸºçº¿ï¼ˆv1.0 æˆ– â€œä»… Markdownâ€ï¼‰ä¸æ ·æœ¬é›†ï¼ˆä¾‹å¦‚ 30 æ¡å…¸å‹é—®é¢˜ï¼‰ã€‚
- ç»Ÿè®¡å£å¾„ï¼šprompt tokens / completion tokens / æ€» tokensã€é¦–å­—å»¶è¿Ÿã€æ£€ç´¢è€—æ—¶ã€ç´¢å¼•è€—æ—¶ã€‚
- ç»™å‡ºé€šè¿‡é˜ˆå€¼ï¼šä¾‹å¦‚â€œå¹³å‡ prompt tokens ä¸‹é™ â‰¥ 50%ï¼ŒåŒæ—¶ç›¸å…³å¬å›å‘½ä¸­ç‡ä¸ä¸‹é™â€ã€‚

---

*Plan Status: Final v2.0*
*Ready for Implementation*
